{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7ef388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RPY2_CFFI_MODE\"] = \"ABI\"\n",
    "import rpy2.robjects as ro\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.rinterface_lib.callbacks import logger as rpy2_logger\n",
    "rpy2_logger.setLevel(\"ERROR\")   # 只显示错误，屏蔽 message 和 warning\n",
    "rpy2_logger.propagate = False   # 阻止继续传给 root logger\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "# from scSurvival.scsurvival import scSurvival, scSurvivalRun, PredictIndSample\n",
    "from scSurvival_beta import scSurvivalRun, PredictIndSample\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import scanpy as sc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import io\n",
    "import contextlib\n",
    "f = io.StringIO()\n",
    "from lifelines.utils import concordance_index\n",
    "from scipy.stats import percentileofscore\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9ae14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_r_packages():\n",
    "    ro.r('''\n",
    "    rm(list=ls())\n",
    "    # library(\"scater\")\n",
    "    library(\"splatter\")\n",
    "    library(scran)\n",
    "    library(Seurat)\n",
    "    # library(preprocessCore)\n",
    "    library(pROC)\n",
    "    # library(APML2)\n",
    "    # library(APML1)\n",
    "    # library(APML0)\n",
    "\n",
    "    library(ggplot2)\n",
    "    library(dplyr)\n",
    "    library(caret)\n",
    "    set.seed(1)\n",
    "    ''')\n",
    "\n",
    "\n",
    "def simulated_base_sc_dataset(seed=42, plot=False, cell_surv_ratio=0.15):\n",
    "    ro.r(f'''\n",
    "    seed <- {seed}\n",
    "    alpha = {cell_surv_ratio}\n",
    "    sim.groups <- splatSimulateGroups(\n",
    "    batchCells = 10000, nGenes=5000,\n",
    "    #group.prob = c(0.9, 0.05, 0.05),\n",
    "    group.prob = c(1 - 2*alpha, alpha, alpha),\n",
    "    de.prob = c(0.2, 0.06, 0.06), \n",
    "    de.facLoc = c(0.1, 0.1, 0.1),\n",
    "    de.facScale = 0.4,\n",
    "    seed = seed)\n",
    "\n",
    "    data <- CreateSeuratObject(counts = counts(sim.groups), project = 'Scissor_Single_Cell')\n",
    "    data <- AddMetaData(object = data, metadata = sim.groups$Group, col.name = \"sim.group\")\n",
    "    data$Actual.cond <- recode(data$sim.group,'Group1'='other', 'Group2'='good.survival', 'Group3'='bad.survival')\n",
    "\n",
    "    select_gene_ids <- 1:2000\n",
    "    data <- NormalizeData(object = data, normalization.method = \"LogNormalize\", \n",
    "                          scale.factor = 10000)\n",
    "    data <- FindVariableFeatures(object = data, selection.method = 'vst', nfeatures=2000)\n",
    "    var_features_genes = VariableFeatures(data)\n",
    "    ''')\n",
    "\n",
    "    if plot:\n",
    "        ro.r('''\n",
    "        data <- ScaleData(object = data)\n",
    "        data <- RunPCA(object = data, features = VariableFeatures(data)[select_gene_ids])\n",
    "\n",
    "        data <- RunUMAP(object = data, dims = 1:10, n.neighbors = 5, min.dist=0.5, spread=1.5)\n",
    "        # data <- RunUMAP(object = data, dims = 1:10)\n",
    "        data <- FindNeighbors(object = data, dims = 1:10, k.param=20)\n",
    "        # data <- FindNeighbors(object = data, dims = 1:10, k.param=20,prune.SNN = 0.2)\n",
    "        data <- FindClusters(object = data, resolution = 0.5)\n",
    "\n",
    "        DimPlot(object = data, reduction = 'umap', group.by = 'seurat_clusters', label = F, label.size = 10,pt.size=0.5)\n",
    "        ggsave(paste0(save_path, 'simu_seurat_cluster_umap.pdf'), height = 5, width = 7)\n",
    "\n",
    "        DimPlot(object = data, reduction = 'umap', group.by = 'sim.group', pt.size = 0.5, label = T)\n",
    "        ggsave(paste0(save_path, 'simu_group_umap.pdf'), height = 5, width = 7)\n",
    "\n",
    "        # DimPlot(object = data, reduction = 'umap',  cols = c('grey','blue', 'red'), group.by = 'sim.group', pt.size = 0.5, label = T)\n",
    "        # \n",
    "        DimPlot(object = data, reduction = 'umap',  cols = c('grey','blue', 'red'), group.by = 'Actual.cond', pt.size = 0.5, label = T)\n",
    "        ggsave(paste0(save_path, 'simu_surv_group_umap.pdf'), height = 5, width = 7)\n",
    "        ''')\n",
    "\n",
    "def simulated_sc_datasets(plot=False, plot_surv=False, censor_prob=0.1, tr=3):\n",
    "    ro.globalenv['censor_prob'] = censor_prob\n",
    "    ro.globalenv['tr'] = tr\n",
    "    ro.r('''\n",
    "    sim_event_time <- function(s, tr) {\n",
    "      alpha = 10  # 尺度参数\n",
    "      gamma_shape = 1.5  # 形状参数\n",
    "\n",
    "      if (tr == 'inf'){\n",
    "        beta_aft = log(20)\n",
    "        U = 0.5\n",
    "      } else{\n",
    "        beta_aft = log(tr)\n",
    "        U = runif(1, 0.2, 0.8) # 避免极端值\n",
    "      }\n",
    "  \n",
    "      T = exp(-beta_aft * s * 2) * (alpha * (-log(U))**(1/gamma_shape))\n",
    "      return(T)\n",
    "    }\n",
    "         \n",
    "    Expression_pbmc <- as.matrix(data@assays[[\"RNA\"]]@layers[[\"data\"]])\n",
    "    rownames(Expression_pbmc) <- rownames(data)\n",
    "    colnames(Expression_pbmc) <- colnames(data)\n",
    "    Expression_pbmc <- as.data.frame(Expression_pbmc)\n",
    "    all_genes <- rownames(Expression_pbmc)\n",
    "         \n",
    "    set.seed(seed)\n",
    "    sampled_cells = 1000\n",
    "    bulk_num=100\n",
    "\n",
    "    other_cells <- colnames(Expression_pbmc)[data$Actual.cond=='other']\n",
    "    good_cells <- colnames(Expression_pbmc)[data$Actual.cond=='good.survival']\n",
    "    bad_cells <- colnames(Expression_pbmc)[data$Actual.cond=='bad.survival']\n",
    "    num_good <- length(good_cells)\n",
    "    num_bad <- length(bad_cells)\n",
    "    bulk_condition = NULL\n",
    "    \n",
    "    # censor_prob\n",
    "    # gamma = log(tr)  # 3\n",
    "\n",
    "    status = NULL\n",
    "    surv_time = NULL\n",
    "\n",
    "    num_good_cond_cells = NULL\n",
    "    num_bad_cond_cells = NULL\n",
    "\n",
    "    sc_data_list = list()\n",
    "    pb <- txtProgressBar(min = 1, max = bulk_num, style = 3)\n",
    "    for (i in 1:bulk_num){\n",
    "      setTxtProgressBar(pb, i)\n",
    "      ratio <- (i-1) / (bulk_num-1)\n",
    "      # ratio <- plogis((ratio - 0.5) * 2 * 6)\n",
    "      num_good_cond_cells_i = round(num_good * ratio)\n",
    "      num_bad_cond_cells_i = round(num_bad * (1-ratio))\n",
    "      condition_good_cells <- good_cells[sample(num_good, num_good_cond_cells_i , replace=TRUE)]\n",
    "      condition_bad_cells <- bad_cells[sample(num_bad, num_bad_cond_cells_i, replace=TRUE)]\n",
    "      condition_cells <- c(condition_good_cells, condition_bad_cells, other_cells)\n",
    "      # condition_cells <- c(condition_bad_cells, other_cells)\n",
    "  \n",
    "      num_good_cond_cells = c(num_good_cond_cells, num_good_cond_cells_i)\n",
    "      num_bad_cond_cells = c(num_bad_cond_cells, num_bad_cond_cells_i)\n",
    "  \n",
    "      Expression_condition = Expression_pbmc[, condition_cells]\n",
    "      Expression_selected <- Expression_condition[, sample(ncol(Expression_condition),size=sampled_cells,replace=TRUE)]\n",
    "  \n",
    "      # filter_cells = intersect(c(condition_bad_cells, other_cells), colnames(Expression_selected))\n",
    "      # Expression_selected <- Expression_selected[, filter_cells]\n",
    "  \n",
    "      # write.csv(Expression_selected, file = sprintf('./source_data/single_cell_revision/%d.csv', i))\n",
    "      sc_data_list[[sprintf('bulk%d', i)]] <- Expression_selected\n",
    "\n",
    "      surv_time_i = sim_event_time(s = (1-ratio), tr = tr)\n",
    "      if (runif(1, min = 0, max = 1) < censor_prob){\n",
    "        status = c(status, 0)\n",
    "        C = runif(1, min = 0, max = surv_time_i)\n",
    "        surv_time = c(surv_time, C)\n",
    "      }\n",
    "      else{\n",
    "        surv_time = c(surv_time, surv_time_i)\n",
    "        status = c(status, 1)\n",
    "      }\n",
    "    }\n",
    "\n",
    "    bulk_names <- paste0('bulk', 1:bulk_num)\n",
    "    surv_info <- data.frame(\n",
    "      time=surv_time,\n",
    "      status=status,\n",
    "      num.good.cells = num_good_cond_cells,\n",
    "      num.bad.cells = num_bad_cond_cells,\n",
    "      row.names = bulk_names\n",
    "    )\n",
    "\n",
    "    dim(surv_info)\n",
    "    dim(Expression_pbmc)\n",
    "         \n",
    "    labels <- data$Actual.cond\n",
    "    labels <- as.data.frame(labels)\n",
    "    row.names(labels) <- colnames(data)\n",
    "    \n",
    "    ''')\n",
    "\n",
    "    if plot:\n",
    "        ro.r('''\n",
    "        library(gridExtra)\n",
    "        library(ggpubr)\n",
    "\n",
    "        plot_list <- list()\n",
    "\n",
    "        for (i in c(2, 10, 40, 60, 90, 99)){\n",
    "          ratio <- (i-1) / (bulk_num-1)\n",
    "          # ratio <- plogis((ratio - 0.5) * 2 * 6)\n",
    "          num_good_cond_cells_i = round(num_good * ratio)\n",
    "          num_bad_cond_cells_i = round(num_bad * (1-ratio))\n",
    "          condition_good_cells <- good_cells[sample(num_good, num_good_cond_cells_i , replace=TRUE)]\n",
    "          condition_bad_cells <- bad_cells[sample(num_bad, num_bad_cond_cells_i, replace=TRUE)]\n",
    "          condition_cells <- c(condition_good_cells, condition_bad_cells, other_cells)\n",
    "          # condition_cells <- c(condition_bad_cells, other_cells)\n",
    "  \n",
    "  \n",
    "          p <- DimPlot(data[, condition_cells], group.by = 'Actual.cond', cols = c('grey','blue', 'red'), pt.size = 0.5) +\n",
    "          ggtitle(sprintf(\"survival.time: %d months\", i))\n",
    "          plot_list[[length(plot_list) + 1]] <- p\n",
    "        }\n",
    "\n",
    "        # combined_plot <- do.call(grid.arrange, c(plot_list, ncol = 3))\n",
    "        # combined_plot\n",
    "        ggarrange(plotlist = plot_list, ncol = 3, nrow=2, common.legend = TRUE, legend = \"bottom\")\n",
    "        ggsave(paste0(save_path, 'survival.time.simulated.pdf'), height = 7, width = 10.5)\n",
    "        ''')\n",
    "      \n",
    "    if plot_surv:\n",
    "        ro.r('''\n",
    "        df <- data.frame(\n",
    "          id = factor(rownames(surv_info), levels = rownames(surv_info)),\n",
    "          start_time = rep(0, dim(surv_info)[1]),\n",
    "          end_time = surv_info$time,          # 事件或删失时间\n",
    "          event = surv_info$status             # 1=事件发生, 0=删失\n",
    "        )\n",
    "\n",
    "\n",
    "        # 把event列转为因子，更清晰地显示legend\n",
    "        df$event <- factor(df$event, levels = c(1, 0), labels = c(\"Event\", \"Censored\"))\n",
    "\n",
    "        # 绘制生存示意图（带legend）\n",
    "        ggplot(df, aes(x = start_time, xend = end_time, y = id, yend = id)) +\n",
    "          geom_segment(size = 1, color = \"gray40\") +\n",
    "          geom_point(aes(x = end_time, shape = event, color = event), size = 2, stroke = 1.5) +\n",
    "          scale_shape_manual(values = c(\"Event\" = 16, \"Censored\" = 4)) +\n",
    "          scale_color_manual(values = c(\"Event\" = \"blue\", \"Censored\" = \"red\")) +\n",
    "          scale_x_continuous(limits = c(0, max(df$end_time) + 1), expand = c(0,0)) +\n",
    "          scale_y_discrete(breaks = function(x) x[seq(1, length(x), by = 5)]) +\n",
    "          labs(x = \"Time (years)\",\n",
    "               y = \"Patient ID\",\n",
    "               shape = \"Status\",\n",
    "               color = \"Status\") +\n",
    "          theme_minimal(base_size = 14) +\n",
    "          theme(\n",
    "            panel.grid = element_blank(),  # 去掉网格\n",
    "            axis.text.x = element_text(angle = 45, hjust = 1),\n",
    "            axis.line.x = element_line(size = 0.8, color = \"black\"),\n",
    "            axis.line.y = element_line(size = 0.8, color = \"black\"),\n",
    "            axis.ticks.x = element_line(size = 0.8, color = \"black\"),\n",
    "            axis.ticks.y = element_line(size = 0.8, color = \"black\"),\n",
    "            legend.position = \"top\"\n",
    "          ) +\n",
    "          coord_flip(clip = \"off\") +     # 保留翻转\n",
    "          expand_limits(x = 0, y = 0)    # 确保从0对齐\n",
    "\n",
    "        ggsave(paste0(save_path, 'Survival_Data_plot.pdf'), width = 6, height = 4)\n",
    "        ''')\n",
    "\n",
    "    # collected sc_data_list, surv_info, Expression_pbmc and transfer to python\n",
    "    surv_info_df     = r_to_pandas(\"surv_info\")\n",
    "    Expression_pbmc_df = r_to_pandas(\"Expression_pbmc\")\n",
    "    sc_data_list     = r_list_to_pydict_df(\"sc_data_list\")  # dict: { 'bulk_1': DataFrame, ... }\n",
    "    labels_df       = r_to_pandas(\"labels\")\n",
    "    features = {\n",
    "        'all_genes': list(ro.r(\"all_genes\")),\n",
    "        'hvg': list(ro.r(\"var_features_genes\"))\n",
    "    }\n",
    "\n",
    "    return_data = {\n",
    "        'sc_data_list': sc_data_list,\n",
    "        'surv_info_df': surv_info_df,\n",
    "        'Expression_pbmc_df': Expression_pbmc_df,\n",
    "        'labels_df': labels_df,\n",
    "        'features': features\n",
    "    }\n",
    "\n",
    "    return return_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_data_for_model(datasets):\n",
    "    sc_data_list = datasets['sc_data_list']\n",
    "    clinic = datasets['surv_info_df']\n",
    "\n",
    "    xs = []\n",
    "    samples = []\n",
    "    for key, val in tqdm(sc_data_list.items()):\n",
    "        df = val\n",
    "        xs.append(df.values.T)\n",
    "        samples.extend([key] * df.shape[1])\n",
    "\n",
    "    X = np.concatenate(xs, axis=0)\n",
    "    adata = sc.AnnData(X, obs=pd.DataFrame(samples, index=np.arange(X.shape[0]), columns=['sample']),\n",
    "    var=pd.DataFrame(index=datasets['features']['all_genes']))\n",
    "\n",
    "    adata.raw = adata.copy()\n",
    "    adata = adata[:, datasets['features']['hvg']]\n",
    "\n",
    "    surv = clinic[['time', 'status']].copy()\n",
    "    surv['time'] = surv['time'].astype(float)\n",
    "    surv['status'] = surv['status'].astype(int)\n",
    "\n",
    "    df = datasets['Expression_pbmc_df']\n",
    "    x = df.values.T\n",
    "    sim_group = datasets['labels_df']\n",
    "    sim_group = sim_group['labels'].values\n",
    "\n",
    "    adata_new = sc.AnnData(x, obs=pd.DataFrame(sim_group, index=np.arange(x.shape[0]), columns=['sim_group']), var=pd.DataFrame(index=datasets['features']['all_genes']))\n",
    "\n",
    "    return adata, surv, adata_new\n",
    "\n",
    "def detect_subpopulations(adata, surv, adata_new, entropy_threshold=0.7):\n",
    "    adata, surv, model = scSurvivalRun(adata, \n",
    "        sample_column='sample',\n",
    "        surv=surv,\n",
    "        # batch_key='batch',\n",
    "        feature_flavor='AE',\n",
    "        entropy_threshold=entropy_threshold,\n",
    "        lambdas=(0.01, 1.0),\n",
    "        pretrain_epochs=200,\n",
    "        epochs=500,\n",
    "        weight_decay=0.01,\n",
    "        lr=0.001,\n",
    "        patience=100,\n",
    "        rec_likelihood='ZIG',\n",
    "        do_scale_ae=False,\n",
    "        beta=0.1, tau=0.2, \n",
    "        sample_size_ae=None,\n",
    "        finetue_lr_factor=0.1,\n",
    "        gene_weight_alpha=0.2,\n",
    "        gamma_beta_weight=(0.1, 0.0),\n",
    "        once_load_to_gpu=True,\n",
    "        use_amp=False,\n",
    "        fitnetune_strategy='alternating', # jointly, alternating, alternating_lightly,\n",
    "        )\n",
    "\n",
    "    data = adata.obs['attention'].values.reshape(-1, 1)\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "    kmeans.fit(data)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    atten_thr = cluster_centers.flatten().mean()\n",
    "    \n",
    "    adata_new, _ = PredictIndSample(adata_new, adata, model)\n",
    "\n",
    "    attention = adata_new.obs['attention'].values\n",
    "    hazard_adj = adata_new.obs['hazard_adj'].values\n",
    "    hazard = adata_new.obs['hazard'].values\n",
    "\n",
    "    risk_group = np.array(['inattentive'] * attention.shape[0], dtype=object)\n",
    "    risk_group[np.logical_and(attention >= atten_thr, hazard_adj > 0)] = 'higher'\n",
    "    risk_group[np.logical_and(attention >= atten_thr, hazard_adj <= 0)] = 'lower'\n",
    "\n",
    "    # higher -> bad.survival, lower -> good.survival, inattentive -> other \n",
    "\n",
    "    risk_group_recoded = np.array(['other'] * attention.shape[0], dtype=object)\n",
    "    risk_group_recoded[risk_group == 'higher'] = 'bad.survival'\n",
    "    risk_group_recoded[risk_group == 'lower'] = 'good.survival'\n",
    "\n",
    "    clf_report = classification_report(adata_new.obs['sim_group'].values, risk_group_recoded, output_dict=True, zero_division=0)\n",
    "\n",
    "    clf_report_df = pd.DataFrame(clf_report).T\n",
    "    return clf_report_df, adata_new\n",
    "\n",
    "def cross_validation_samples(adata, surv, entropy_threshold=0.7):\n",
    "    # 交叉验证样本\n",
    "    adata = adata.raw.to_adata()\n",
    "    adata.obs['patient_no'] = adata.obs['sample']\n",
    "    patients = adata.obs['patient_no'].unique()\n",
    "\n",
    "    # K fold cross validation\n",
    "    cv_hazards_adj_cells = np.zeros((adata.shape[0], ))\n",
    "    surv['cv_hazards_adj_patient'] = 0.0\n",
    "    surv['cv_hazard_percentile_patient'] = 0.0\n",
    "    cindexs = []\n",
    "    surv_test_all_folds = []\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(patients)):\n",
    "\n",
    "        print(f'fold {i}, train_size: {train_index.shape[0]}, test_size: {test_index.shape[0]}')\n",
    "        train_patients = patients[train_index]\n",
    "        test_patients = patients[test_index]\n",
    "\n",
    "        # train\n",
    "        adata_train = adata[adata.obs['patient_no'].isin(train_patients), :].copy()\n",
    "    \n",
    "        ## select HVGs on training set only\n",
    "        sc.pp.highly_variable_genes(adata_train, n_top_genes=2000, subset=False, flavor='seurat')\n",
    "        hvgs = adata_train.var[adata_train.var['highly_variable']].index.tolist() \n",
    "        adata_train = adata_train[:, hvgs]\n",
    "\n",
    "        surv_train = surv.loc[surv.index.isin(train_patients), :].copy()\n",
    "\n",
    "        adata_train, surv_train, model = scSurvivalRun(\n",
    "            adata_train,\n",
    "            sample_column='sample',\n",
    "            surv=surv_train,\n",
    "            # batch_key='batch',\n",
    "            feature_flavor='AE',\n",
    "            entropy_threshold=entropy_threshold,\n",
    "            validate=True,\n",
    "            validate_ratio=0.2,\n",
    "            validate_metric='ccindex',\n",
    "            lambdas=(0.01, 1.0),\n",
    "            pretrain_epochs=200,\n",
    "            epochs=500,\n",
    "            weight_decay=0.01,\n",
    "            lr=0.001,\n",
    "            patience=100,\n",
    "            rec_likelihood='ZIG',\n",
    "            do_scale_ae=False,\n",
    "            beta=0.1, tau=0.2, \n",
    "            sample_size_ae=None,\n",
    "            finetue_lr_factor=0.1,\n",
    "            gene_weight_alpha=0.2,\n",
    "            gamma_beta_weight=(0.1, 0.0),\n",
    "            once_load_to_gpu=True,\n",
    "            use_amp=False,\n",
    "            fitnetune_strategy='alternating', # jointly, alternating, alternating_lightly,\n",
    "            )  \n",
    "        \n",
    "        \n",
    "        train_cindex = concordance_index(surv_train['time'], -surv_train['patient_hazards'], surv_train['status'])\n",
    "        print(f'train c-index: {train_cindex:.4f}')\n",
    "\n",
    "        # test\n",
    "        print('testing...')\n",
    "        adata_test = adata[adata.obs['patient_no'].isin(test_patients), :].copy()\n",
    "        adata_test = adata_test[:, hvgs]\n",
    "\n",
    "        with contextlib.redirect_stdout(f):\n",
    "            for test_patient in test_patients:\n",
    "                adata_test_patient = adata_test[adata_test.obs['patient_no'] == test_patient, :].copy()\n",
    "                adata_test_patient, patient_hazard = PredictIndSample(adata_test_patient, adata_train, model)\n",
    "                cv_hazards_adj_cells[adata.obs['patient_no'] == test_patient] = adata_test_patient.obs['hazard_adj'].values\n",
    "                surv.loc[surv.index == test_patient, 'cv_hazards_adj_patient'] = patient_hazard\n",
    "                surv.loc[surv.index == test_patient, 'cv_hazard_percentile_patient'] = percentileofscore(surv_train['patient_hazards'], patient_hazard, kind='rank')\n",
    "\n",
    "        surv_test = surv.loc[surv.index.isin(test_patients), :]\n",
    "        c_index = concordance_index(surv_test['time'], -surv_test['cv_hazards_adj_patient'], surv_test['status'])\n",
    "\n",
    "        cindexs.append(c_index)\n",
    "        surv_test_all_folds.append(surv_test)\n",
    "\n",
    "        print(f'c-index: {c_index:.4f}')\n",
    "        print('='*50)\n",
    "\n",
    "        # if i == 0:\n",
    "        #     break\n",
    "\n",
    "    mean_cindex = np.mean(cindexs)\n",
    "    std_cindex = np.std(cindexs)\n",
    "\n",
    "    print(f'mean c-index: {mean_cindex:.4f} ± {std_cindex:.4f}')\n",
    "    cindexs_df = pd.DataFrame(cindexs, columns=['c-index'], index=['fold%d' % i for i in range(5)])\n",
    "\n",
    "    cindex_results = {\n",
    "        'mean_cindex': mean_cindex,\n",
    "        'std_cindex': std_cindex,\n",
    "        'cindexs_df': cindexs_df\n",
    "    }\n",
    "\n",
    "    return cindex_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bff430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Logger\n",
    "from itertools import product\n",
    "load_r_packages()\n",
    "param_grid = {\n",
    "    'seed': range(1, 11),\n",
    "    'censor_prob': [0.2, 0.5, 0.7],\n",
    "    'tr': ['inf', 3, 2, 1.3]\n",
    "}\n",
    "keys, values = zip(*param_grid.items())\n",
    "combos = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "save_root_path = './results/revision-sim3-python/'\n",
    "logger = Logger(save_path=f'{save_root_path}cell_subpopulation_logs_continue_3.csv')\n",
    "\n",
    "for i, params in enumerate(combos):\n",
    "\n",
    "    if i < 78:\n",
    "        continue\n",
    "\n",
    "    logger.log_dict(params)\n",
    "    seed = params['seed']\n",
    "    censor_prob = params['censor_prob']\n",
    "    tr = params['tr']\n",
    "\n",
    "    print(f'Running {i+1}/{len(combos)}: seed={seed}, censor_prob={censor_prob}, tr={tr}')\n",
    "\n",
    "    save_path = f'{save_root_path}/censor-{censor_prob}_tr-{tr}_seed-{seed}/'\n",
    "    ro.globalenv['save_path'] = save_path\n",
    "    \n",
    "    if seed == 1:\n",
    "        ro.r('dir.create(save_path, recursive=T)')\n",
    "        if i == 0:\n",
    "            simulated_base_sc_dataset(seed=seed, plot=True)\n",
    "            datasets = simulated_sc_datasets(plot=True, plot_surv=True, censor_prob=censor_prob, tr=tr)\n",
    "        else:\n",
    "            simulated_base_sc_dataset(seed=seed, plot=False)\n",
    "            datasets = simulated_sc_datasets(plot=False, plot_surv=True, censor_prob=censor_prob, tr=tr)\n",
    "    else:\n",
    "        simulated_base_sc_dataset(seed=seed, plot=False)\n",
    "        datasets = simulated_sc_datasets(plot=False, plot_surv=False, censor_prob=censor_prob, tr=tr)\n",
    "\n",
    "    adata, surv, adata_new = organize_data_for_model(datasets)\n",
    "    clf_report_df, adata_new = detect_subpopulations(adata, surv, adata_new, entropy_threshold=0.7)\n",
    "\n",
    "    clf_rst = {\n",
    "        'precision': clf_report_df.loc['macro avg', 'precision'],\n",
    "        'recall': clf_report_df.loc['macro avg', 'recall'],\n",
    "        'f1-score': clf_report_df.loc['macro avg', 'f1-score'],\n",
    "    }\n",
    "\n",
    "    for cls in ['good.survival', 'bad.survival', 'other']:\n",
    "        for metric in ['precision', 'recall', 'f1-score']:\n",
    "            key = f'{cls}_{metric}'\n",
    "            if cls in clf_report_df.index:\n",
    "                clf_rst[key] = clf_report_df.loc[cls, metric]\n",
    "            else:\n",
    "                clf_rst[key] = 0.0\n",
    "\n",
    "    logger.log_dict(clf_rst)\n",
    "    logger.get_logs_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_r_packages()\n",
    "param_grid = {\n",
    "    'seed': [1],\n",
    "    'censor_prob': [0.2, 0.5, 0.7],\n",
    "    'tr': ['inf', 1.3, 2, 3]\n",
    "}\n",
    "keys, values = zip(*param_grid.items())\n",
    "combos = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "save_root_path = './results/revision-sim3-python/'\n",
    "logger = Logger(save_path=f'{save_root_path}cv_logs.csv')\n",
    "\n",
    "for i, params in enumerate(combos):\n",
    "    logger.log_dict(params)\n",
    "\n",
    "    seed = params['seed']\n",
    "    censor_prob = params['censor_prob']\n",
    "    tr = params['tr']\n",
    "\n",
    "    print(f'Running {i+1}/{len(combos)}: seed={seed}, censor_prob={censor_prob}, tr={tr}')\n",
    "\n",
    "    simulated_base_sc_dataset(seed=seed, plot=False)\n",
    "    datasets = simulated_sc_datasets(plot=False, plot_surv=False, censor_prob=censor_prob, tr=tr)\n",
    "\n",
    "    adata, surv, adata_new = organize_data_for_model(datasets)\n",
    "    cindex_results = cross_validation_samples(adata, surv, entropy_threshold=0.7)\n",
    "\n",
    "    cindex_results = {\n",
    "        'mean_cindex': cindex_results['mean_cindex'],\n",
    "        'std_cindex': cindex_results['std_cindex']\n",
    "    }\n",
    "\n",
    "    logger.log_dict(cindex_results)\n",
    "    logger.get_logs_df()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
